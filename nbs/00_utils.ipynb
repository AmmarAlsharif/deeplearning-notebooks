{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! pip install nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import re\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import notebook\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.train import CheckpointManager\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def copy_data(source:Path, dest:Path, copy_rate:float):\n",
    "    ''' Copy data from source path to dest (destination) path\n",
    "        Args:\n",
    "            soucre: path of the data source\n",
    "            dest: path where to copy the data\n",
    "            copy_rate: percentage of how many data to copy from the source\n",
    "    '''\n",
    "    fnames = os.listdir(source)\n",
    "    data_size = len(fnames)\n",
    "    train_data_size = int(data_size * copy_rate)\n",
    "    for idx, fname in enumerate(fnames):\n",
    "        src = source / fname\n",
    "        if idx + 1 > train_data_size:\n",
    "            break\n",
    "        if os.path.getsize(src) == 0 or imghdr.what(src) != 'jpeg':\n",
    "            print(\"Ignoring {}, because it's a corrupted file\".format(fname))\n",
    "            continue\n",
    "        copyfile(src, dest / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide\n",
    "# def how_many_in_each_class(root_dir ,classes):\n",
    "#     output = {}\n",
    "#     for class_name in classes:\n",
    "#         output[class_name.upper()] = len(os.listdir(root_dir / class_name))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def how_many_in_each_class(root_dir:Path,classes:List[str]):\n",
    "    for class_name in classes:\n",
    "        print('class: {} has: {} images'.format(class_name.upper(),len(os.listdir(root_dir / class_name))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def freeze_unfreeze_layers(model:tf.keras.Model, layers:List[str] = [], freeze_mode:bool = True):\n",
    "    '''freeze unfreeze layers for a given model\n",
    "        Args:\n",
    "            model: The model to freeze unfreeze its layers\n",
    "            layers: a list of layers to be frozen unfrozen\n",
    "                    empty list means the operation will be \n",
    "                    applied to all layers of the given model\n",
    "            freeze_mode: True to freeze the layers,\n",
    "                         False to unfreeze the layers\n",
    "    '''\n",
    "    trainable = not(freeze_mode)\n",
    "    if len(layers) == 0:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = trainable\n",
    "        return\n",
    "    for layer in layers:\n",
    "        model.get_layer(layer).trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def list_layers(model:tf.keras.Model):\n",
    "    ''' List all layers of a given model '''\n",
    "    for layer in model.layers:\n",
    "        print('name: {}, trainable: {}'.format(layer.name, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def evaluate(model:tf.keras.Model, test_ds:tf.data.Dataset, metric:tf.metrics.Metric, num_batches:int = None):\n",
    "    prog_bar = tf.keras.utils.Progbar(target=num_batches)\n",
    "    for idx, batch in enumerate(test_ds):\n",
    "        metric(batch[1], model(batch[0], training=False))\n",
    "        prog_bar.update(idx)\n",
    "    print()\n",
    "    print(\"{}: {:.2f}\".format(metric.name, metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CheckPointManagerCallback(Callback):\n",
    "    ''' Keras Callback for the tf.train.CheckPointManager\n",
    "        All arguments are same as in the tf.train.CheckPointManager\n",
    "        except the `after_num_epoch`\n",
    "        Args: \n",
    "            after_num_epoch: number of epochs between each check point save \n",
    "    '''\n",
    "    def __init__(self, \n",
    "                checkpoint,\n",
    "                directory,\n",
    "                max_to_keep,\n",
    "                after_num_epoch=1,\n",
    "                keep_checkpoint_every_n_hours=None,\n",
    "                checkpoint_name=\"ckpt\",\n",
    "                step_counter=None,\n",
    "                checkpoint_interval=None,\n",
    "                init_fn=None):\n",
    "        super().__init__()\n",
    "        self.manager = (CheckpointManager(checkpoint,  \n",
    "                                          directory, \n",
    "                                          max_to_keep, \n",
    "                                          keep_checkpoint_every_n_hours, \n",
    "                                          checkpoint_name, \n",
    "                                          step_counter, \n",
    "                                          checkpoint_interval, \n",
    "                                          init_fn))\n",
    "        self.epoch_counter = 0\n",
    "        self.after_num_epoch = after_num_epoch\n",
    "    \n",
    "    def on_epoch_end(self,batch, logs={}):\n",
    "        self.epoch_counter += 1\n",
    "        if self.epoch_counter % self.after_num_epoch == 0:\n",
    "            self.manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import time\n",
    "\n",
    "def timeit(dataset, steps=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    for step in range(steps):\n",
    "        next_batch = next(iterator)\n",
    "        if step % 10 == 0:\n",
    "            print('.', end='')\n",
    "    print()\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = (end_time - start_time)\n",
    "    \n",
    "    print('{} batches: {} s'.format(steps, (duration)))\n",
    "    print('{:.4f} Images/s'.format(batch_size * steps / duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _validate_url(url):\n",
    "    regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://' # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "            r'localhost|' #localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "            r'(?::\\d+)?' # optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "    return re.match(regex, url) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_images(dest, file, counter = 0):\n",
    "    urls = open(file).read().strip().split(\"\\n\")\n",
    "    for idx, url in enumerate(urls):\n",
    "        if not(_validate_url(url)): continue\n",
    "        resp = requests.get(url, allow_redirects=False)\n",
    "        suffix = '.jpg'\n",
    "        img_name = str(idx + counter)\n",
    "        img_full_name = str(dest/img_name) + suffix\n",
    "        open(img_full_name,'wb').write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def verify_images(dest:Path, delete:bool=False, n_channels:int=3):\n",
    "    fnames = os.listdir(str(dest))\n",
    "    for fname in notebook.tqdm(fnames ,total=len(fnames)):\n",
    "        if not(verify_image(dest/fname, n_channels)):\n",
    "            if delete:\n",
    "                os.remove(dest/fname)\n",
    "                print('{} => corrupted image, so it was deleted'.format(dest/fname))\n",
    "                continue\n",
    "            print('{} => corrupted image, pass `delete=True` to delete corrupted images'.format(dest/fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def verify_image(img_path, n_channels):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img.draft(img.mode,(28,28))\n",
    "        img.load()\n",
    "        return imghdr.what(img_path) != None and  img.layers == n_channels\n",
    "    except: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted Custom_Training_with_Custom_Loss_MNIST_FASHION.ipynb.\n",
      "Converted Flowers_Classifier.ipynb.\n",
      "Converted Improved_Data_Pipelines_for_Small_Datasets_Tensorflow_2.x.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "! nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating public/private rsa key pair.\n",
      "Enter file in which to save the key (/root/.ssh/id_rsa): \n",
      "Created directory '/root/.ssh'.\n",
      "Enter passphrase (empty for no passphrase): 159753\n",
      "Enter same passphrase again: 159753\n",
      "Your identification has been saved in /root/.ssh/id_rsa.\n",
      "Your public key has been saved in /root/.ssh/id_rsa.pub.\n",
      "The key fingerprint is:\n",
      "SHA256:uB5I2ND1myPqQNVwhF8773frwu80OtnGSrxhepzT5T0 root@83f1cf00cf8c\n",
      "The key's randomart image is:\n",
      "+---[RSA 2048]----+\n",
      "|    .o+          |\n",
      "|   ..= ..        |\n",
      "|  . o.....       |\n",
      "|   =  ..oo       |\n",
      "|  o o o So       |\n",
      "| . . o o ...    .|\n",
      "|  . o o  . o=*oo.|\n",
      "|   o . .  .+@=*Eo|\n",
      "|    . .   .o+@=..|\n",
      "+----[SHA256]-----+\n"
     ]
    }
   ],
   "source": [
    "! ssh-keygen -t rsa -b 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDGTE+YTqLtr5wQvTVqR7K3IXV0MTBsfxIeT03ocBLXzakiOVL9aqlhYxmpjVhKyKZWV5U1NDPo0901ycvg9nYogDsfJ9+3wkJawR03O0yHbNRX9yO/9sJnUaOT9YtKN/QpFAC7rG+3+248tqPJNbrGjutkHeRWCSeaBRJcl6i4KjjlgTPiri0q/YepbgfYCyCmMKF6uOe97DNv3EMsUc3tCc1vgWPHYHF31vgfteG1kQh4VydJLLdmLgalk1V1Vpab5q3g0aD7CLMCRR4Rad3JSvNuGwuSNqWNldXAz/JxG4Tc7py1hNHNOSuwGKzy9Hp7f/Cx52V1aIkgX9TeZh3D root@83f1cf00cf8c\n"
     ]
    }
   ],
   "source": [
    "! cd /root/.ssh && cat id_rsa.pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: git config --local include.path ../.gitconfig\n",
      "Success: hooks are installed and repo's .gitconfig is now trusted\n"
     ]
    }
   ],
   "source": [
    "! nbdev_install_git_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
